{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "class KNNClassifier:\n",
    "    k = None\n",
    "    encoded_train_data = pd.DataFrame()\n",
    "    \n",
    "    def find_one_hot_encoding(self,train_data_frm):\n",
    "        lis = [\n",
    "             ['b','c','x','f','k','s'],\n",
    "           ['f', 'g' , 'y', 's'],\n",
    "           ['n', 'b', 'c', 'g', 'r', 'p', 'u', 'e', 'w', 'y']\n",
    "            ,['t', 'f'],\n",
    "           ['a', 'l', 'c', 'y', 'f', 'm', 'n', 'p', 's'],\n",
    "             ['a', 'f', 'd', 'n'],\n",
    "           ['c', 'w' , 'd'],\n",
    "             ['b', 'n'],\n",
    "           ['k', 'n' , 'b', 'h', 'g', 'r', 'o', 'p', 'u', 'e', 'w', 'y']  \n",
    "              , ['e', 't'] ,\n",
    "           ['b','c','u','e','z','r'],\n",
    "              ['f', 'y' , 'k', 's'],\n",
    "              ['f', 'y' , 'k', 's'],\n",
    "              ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'],\n",
    "              ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'],\n",
    "              ['p', 'u'],\n",
    "               ['n', 'o', 'w', 'y'],\n",
    "              ['n', 'o', 't'],\n",
    "              ['c', 'e', 'f', 'l', 'n', 'p', 's', 'z'],\n",
    "              ['k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y'],\n",
    "               ['a', 'c', 'n', 's', 'v', 'y'],\n",
    "              ['g', 'l', 'm', 'p', 'u', 'w', 'd']\n",
    "          ]\n",
    "        new_train_data_frame = pd.DataFrame()\n",
    "        column_names = list(train_data_frm.columns)\n",
    "        for index in range(len(column_names)):\n",
    "            new_df = pd.get_dummies(train_data_frm[column_names[index]],columns=lis[index])\n",
    "            new_df = new_df.T.reindex(lis[index]).T.fillna(0)\n",
    "            new_train_data_frame = pd.concat([new_train_data_frame, new_df], axis=1)\n",
    "#             print(new_train_data_frame)\n",
    "        return new_train_data_frame\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    def train_validation_split(self,data_frm,validation_data_size):\n",
    "        if isinstance(validation_data_size, float):\n",
    "            validation_data_size=round(validation_data_size * len(data_frm))\n",
    "\n",
    "        indices=data_frm.index.tolist()\n",
    "\n",
    "        valid_indices=random.sample(indices, validation_data_size)\n",
    "        valid_datafrm=data_frm.loc[valid_indices]\n",
    "\n",
    "        train_datafrm=data_frm.drop(valid_indices)\n",
    "\n",
    "        return train_datafrm , valid_datafrm\n",
    "    \n",
    "    def createDistanceLabelEuclidean(self, test_sample):\n",
    "        results_dist_label=[]\n",
    "        for li in self.encoded_train_data:\n",
    "            test_list=test_sample[0:]\n",
    "            train_list=li[1:]\n",
    "            dist=np.linalg.norm(test_list-train_list)\n",
    "            results_dist_label.append([dist,li[0]])\n",
    "\n",
    "        results_dist_label.sort()\n",
    "\n",
    "        return results_dist_label\n",
    "    \n",
    "    def createDistanceLabelManhattan(self, test_sample):\n",
    "        results_dist_label=[]\n",
    "        for li in self.train_data:\n",
    "            test_list=test_sample[0:]\n",
    "            train_list=li[1:]\n",
    "            dist=np.sum(np.absolute(test_list - train_list))\n",
    "            results_dist_label.append([dist,li[0]])\n",
    "\n",
    "        results_dist_label.sort()\n",
    "\n",
    "        return results_dist_label\n",
    "    \n",
    "    def getPredictedLabelValue(self,results_dist_label):\n",
    "        label_count={}\n",
    "        for i in range(self.k):\n",
    "            val = results_dist_label[i][1]\n",
    "            if val in label_count:\n",
    "                label_count[val]+=1\n",
    "            else:\n",
    "                label_count[val]=1\n",
    "\n",
    "    #     for ky,vl in label_count.items():\n",
    "    #         print(ky,\":\",vl)\n",
    "\n",
    "        return max(label_count,key=label_count.get)\n",
    "    \n",
    "    \n",
    "    def getPredictedLabels(self, validation_data):\n",
    "        predicted_list=[]\n",
    "\n",
    "        for test_sample in validation_data:\n",
    "            results_dist_label = self.createDistanceLabelEuclidean(test_sample)\n",
    "            predicted_label = self.getPredictedLabelValue(results_dist_label)\n",
    "            predicted_list.append(predicted_label)\n",
    "        return predicted_list \n",
    "    \n",
    "    \n",
    "    def check_validation(self,train_data_frm, validation_data_size):\n",
    "        random.seed(0)\n",
    "        train_data_frm , validation_data_frm = self.train_validation_split(train_data_frm, validation_data_size)\n",
    "            \n",
    "        self.encoded_train_data = train_data_frm.iloc[:,0].to_frame()\n",
    "        train_data_frm = train_data_frm.drop([train_data_frm.columns[0]],  axis='columns')\n",
    "        encoded_train_features = self.find_one_hot_encoding(train_data_frm)\n",
    "        self.encoded_train_data = pd.concat([self.encoded_train_data, encoded_train_features], axis=1).values\n",
    "        \n",
    "        validation_data_labels = validation_data_frm.iloc[:,0].to_frame()\n",
    "        validation_data_frm = validation_data_frm.drop([validation_data_frm.columns[0]],  axis='columns')\n",
    "        encoded_validation_features = self.find_one_hot_encoding(validation_data_frm)\n",
    "#         encoded_validation_features.info()\n",
    "        \n",
    "        predicted_labels = self.getPredictedLabels(encoded_validation_features.values)\n",
    "        print(accuracy_score(validation_data_labels.values.tolist(), predicted_labels))\n",
    "            \n",
    "    \n",
    "    def prepare_data(self,train_data_frm):\n",
    "#         col_values = train_data_frm.iloc[:,11]\n",
    "#         cal_mode = col_values.mode()[0]\n",
    "#         train_data_frm.replace(to_replace='?', value=cal_mode, inplace=True)\n",
    "\n",
    "        for col_name in train_data_frm.columns:\n",
    "            mode_val = train_data_frm[col_name].mode()[0]\n",
    "            train_data_frm.replace(to_replace='?', value=mode_val, inplace=True)\n",
    "\n",
    "        return train_data_frm\n",
    "    \n",
    "    def train(self,train_path):\n",
    "        train_data_frm = pd.read_csv(train_path, header=None)\n",
    "        self.k=3\n",
    "        train_data_frm = self.prepare_data(train_data_frm)\n",
    "#         self.check_validation(train_data_frm, 10)\n",
    "        self.encoded_train_data = train_data_frm.iloc[:,0].to_frame()\n",
    "        train_data_frm = train_data_frm.drop([train_data_frm.columns[0]],  axis='columns')\n",
    "        encoded_train_features = self.find_one_hot_encoding(train_data_frm)\n",
    "        self.encoded_train_data = pd.concat([self.encoded_train_data, encoded_train_features], axis=1).values\n",
    "#         print(self.encoded_train_data.shape)\n",
    "               \n",
    "    def predict(self,test_path):\n",
    "        test_data_frm = pd.read_csv(test_path,header=None)\n",
    "        test_data_frm = self.prepare_data(test_data_frm)\n",
    "        encoded_test_data = self.find_one_hot_encoding(test_data_frm)\n",
    "        predicted_labels = self.getPredictedLabels(encoded_test_data.values)\n",
    "        return predicted_labels\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# knn_classifier = KNNClassifier()\n",
    "# knn_classifier.train('/home/jyoti/Documents/SMAI/assign1/q2/train.csv')\n",
    "# predictions = knn_classifier.predict('/home/jyoti/Documents/SMAI/assign1/q2/test.csv')\n",
    "# test_labels = list()\n",
    "# with open('/home/jyoti/Documents/SMAI/assign1/q2/test_labels.csv') as f:\n",
    "#   for line in f:\n",
    "#     test_labels.append(line.strip())\n",
    "# print (accuracy_score(test_labels, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
